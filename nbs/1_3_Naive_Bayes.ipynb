{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322e1922-97df-48ba-b769-feec55724393",
   "metadata": {},
   "source": [
    "# Naive Bayes Sentiment Classifier\n",
    "> This module defines a sentiment classifier that implements the naive bayes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de54f4d5-52be-42d9-aa27-c1e58ab817d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T11:37:10.539392Z",
     "iopub.status.busy": "2023-02-22T11:37:10.538392Z",
     "iopub.status.idle": "2023-02-22T11:37:10.551399Z",
     "shell.execute_reply": "2023-02-22T11:37:10.549391Z",
     "shell.execute_reply.started": "2023-02-22T11:37:10.539392Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| default_exp naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b219d624-f495-4fc8-a2d6-0b4c07b5aced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T11:37:10.561392Z",
     "iopub.status.busy": "2023-02-22T11:37:10.561392Z",
     "iopub.status.idle": "2023-02-22T11:37:11.644108Z",
     "shell.execute_reply": "2023-02-22T11:37:11.641377Z",
     "shell.execute_reply.started": "2023-02-22T11:37:10.561392Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b44173b-3390-425f-bdd2-9cfb9cd64ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T11:37:11.657195Z",
     "iopub.status.busy": "2023-02-22T11:37:11.657047Z",
     "iopub.status.idle": "2023-02-22T11:37:11.704016Z",
     "shell.execute_reply": "2023-02-22T11:37:11.703057Z",
     "shell.execute_reply.started": "2023-02-22T11:37:11.657195Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def read_reviews(path: str # The path to the folder containing the subdirectories 'pos' and 'neg'.\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Given a path, reads the data from the two subdirectories 'pos' and 'neg'.\n",
    "\n",
    "    Parameters:\n",
    "        - path (str): The path to the folder containing the subdirectories 'pos' and 'neg'.\n",
    "\n",
    "    Returns:\n",
    "    - A list of reviews as strings\n",
    "    \"\"\"\n",
    "\n",
    "    reviews = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(path, filename), \"r\", encoding=\"utf8\") as f:\n",
    "                review = f.read().strip()\n",
    "                reviews.append(review)\n",
    "    return reviews\n",
    "\n",
    "def create_dataframe(path: str # The path to the folder containing the subdirectories 'pos' and 'neg'.\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Creates a pandas dataframe with two columns, Review (this is the review from the text file)\n",
    "    and Label (this contains 'positive' or 'negative' if it came from the 'pos' or 'neg' subdirectory respectively).\n",
    "\n",
    "    Parameters:\n",
    "        - folder_path (str): The path to the folder containing the subdirectories 'pos' and 'neg'.\n",
    "\n",
    "    Returns:\n",
    "    - A pandas dataframe with two columns, Review and Label.\n",
    "    \"\"\"\n",
    "    pos_path = os.path.join(path, \"pos\")\n",
    "    neg_path = os.path.join(path, \"neg\")\n",
    "\n",
    "    # Read in all the positive and negative reviews\n",
    "    pos_reviews = read_reviews(pos_path)\n",
    "    neg_reviews = read_reviews(neg_path)\n",
    "\n",
    "    # Create a pandas dataframe with the reviews and labels\n",
    "    reviews = pos_reviews + neg_reviews\n",
    "    labels = [\"positive\"] * len(pos_reviews) + [\"negative\"] * len(neg_reviews)\n",
    "    data = {\"Review\": reviews, \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def clean_review(review: str # The review to be cleaned.\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Cleans a review by converting text to lowercase, removing numbers and punctuation, stop words (specified in the function) and extra whitespace.\n",
    "\n",
    "    Parameters:\n",
    "        - review (str): The review to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    - A list of clean words.\n",
    "    \"\"\"\n",
    "    # Remove stop words and extra whitespace\n",
    "    clean_words = review.split()\n",
    "\n",
    "    return clean_words\n",
    "\n",
    "\n",
    "def read_test_file(file_path: str # Path to the file to read\n",
    "                     ) -> pd.Series:\n",
    "    '''\n",
    "    Reads a file given a path to the file where every line in the file is one review, \n",
    "    transforms the file and returns it as a pandas series.\n",
    "    \n",
    "    Parameters:\n",
    "        - file_path (str): Path to the file to read\n",
    "    \n",
    "    Returns:\n",
    "        - pandas.Series: A pandas series where each element is a review from the file\n",
    "    '''\n",
    "    \n",
    "    # Open file and read lines into a list\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        reviews_list = f.readlines()\n",
    "\n",
    "    # Strip whitespace from each line and create pandas series\n",
    "    reviews = pd.Series([review.strip() for review in reviews_list])\n",
    "\n",
    "    return reviews\n",
    "\n",
    "class NaiveBayesSentimentClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prior_positive = 0.0\n",
    "        self.prior_negative = 0.0\n",
    "        self.word_count_positive = defaultdict(int)\n",
    "        self.word_count_negative = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "    \n",
    "    def train(self, \n",
    "              df:pd.DataFrame, # A dataframe containing two columns: 'CleanReview' (contains lists of words) and 'Label' (contains either 'positive' or 'negative')\n",
    "              alpha:float=1.0 # Smoothing parameter for Laplace smoothing (default 1.0).\n",
    "             ):\n",
    "        '''\n",
    "        Trains a Naive Bayes sentiment classifier on a given dataframe.\n",
    "        \n",
    "        Parameters:\n",
    "            - df (pd.DataFrame): A dataframe containing two columns:\n",
    "                                 'CleanReview' (contains lists of words from review) and\n",
    "                                 'Label' (contains either 'positive' or 'negative')\n",
    "            - alpha (float): Smoothing parameter for Laplace smoothing (default 1.0).\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        # Splitting up positive and negative reviews\n",
    "        positive_reviews = df[df['Label'] == 'positive']\n",
    "        negative_reviews = df[df['Label'] == 'negative']\n",
    "        \n",
    "        # Calculating the prior probabilites of each class\n",
    "        self.prior_positive = len(positive_reviews) / len(df)\n",
    "        self.prior_negative = len(negative_reviews) / len(df)\n",
    "        \n",
    "        # Creating a positive word count and developing the vocabulary\n",
    "        for _, row in positive_reviews.iterrows():\n",
    "            for word in row['CleanReview']:\n",
    "                self.word_count_positive[word] += 1\n",
    "                self.vocab.add(word)\n",
    "\n",
    "        # Creating a negative word count and developing the vocabulary\n",
    "        for _, row in negative_reviews.iterrows():\n",
    "            for word in row['CleanReview']:\n",
    "                self.word_count_negative[word] += 1\n",
    "                self.vocab.add(word)\n",
    "        \n",
    "        self.prob_word_given_positive = defaultdict(float)\n",
    "        self.prob_word_given_negative = defaultdict(float)\n",
    "        \n",
    "        total_count_positive = sum(self.word_count_positive.values())\n",
    "        total_count_negative = sum(self.word_count_negative.values())\n",
    "        \n",
    "        # Calculating the probabilities for each word given a class and Laplace Smoothing\n",
    "        # P(word|label) = Number of occurences of a word for a class / Total number of occurances for the class\n",
    "        for word in self.vocab:\n",
    "            self.prob_word_given_positive[word] = (self.word_count_positive[word] + alpha) / (total_count_positive + alpha*len(self.vocab))\n",
    "            self.prob_word_given_negative[word] = (self.word_count_negative[word] + alpha) / (total_count_negative + alpha*len(self.vocab))\n",
    "\n",
    "    def predict(self, reviews:pd.Series) -> pd.Series:\n",
    "        '''\n",
    "        Predicts the sentiment for a given dataframe of reviews.\n",
    "        \n",
    "        Parameters:\n",
    "            - df (pd.DataFrame): A dataframe containing one column: 'CleanReview' (contains lists of words) and 'Label' (optional).\n",
    "        \n",
    "        Returns:\n",
    "            A dataframe with two columns: 'Prediction' (contains either 'positive' or 'negative') and 'Probability' (contains the probability of the prediction).\n",
    "        '''\n",
    "        \n",
    "        # Create a results dataframe\n",
    "        predictions = []\n",
    "        probs_positive = []\n",
    "        probs_negative = []\n",
    "        \n",
    "        for review in reviews:\n",
    "            \n",
    "            # Initialising the probabilities\n",
    "            prob_positive = math.log(self.prior_positive)\n",
    "            prob_negative = math.log(self.prior_negative)\n",
    "            \n",
    "            # Add probabilities for each word        \n",
    "            for word in review:\n",
    "                if word in self.vocab:\n",
    "                    prob_positive += math.log(self.prob_word_given_positive[word])\n",
    "                    prob_negative += math.log(self.prob_word_given_negative[word])\n",
    "            \n",
    "            # Add Probabilites\n",
    "            probs_positive.append(prob_positive)\n",
    "            probs_negative.append(prob_negative)\n",
    "            \n",
    "            # If it's more likely to be positive, predict positive else predict negative\n",
    "            if prob_positive > prob_negative:\n",
    "                predictions.append('positive')\n",
    "                \n",
    "            else:\n",
    "                predictions.append('negative')\n",
    "        \n",
    "        # Add the predictions and probabiities\n",
    "        self.test_reviews = reviews\n",
    "        self.predictions = pd.Series(predictions)\n",
    "        self.probs_positive = pd.Series(probs_positive)\n",
    "        self.probs_negative = pd.Series(probs_negative)\n",
    "        return self.predictions \n",
    "    \n",
    "    def evaluate(self, labels:pd.Series) -> float:\n",
    "        '''\n",
    "        Evaluates the accuracy of the sentiment predictions.\n",
    "\n",
    "        Parameters:\n",
    "            - No parameters as it uses df_results\n",
    "\n",
    "        Returns:\n",
    "            - accuracy (float): The accuracy of the sentiment predictions\n",
    "        '''\n",
    "        self.labels = labels\n",
    "        \n",
    "        total_predictions = len(self.predictions)\n",
    "\n",
    "        correct_predictions = (self.predictions == self.labels).sum()\n",
    "\n",
    "        self.accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        return self.accuracy\n",
    "\n",
    "\n",
    "def run_naive_bayes(train_file, test_file):\n",
    "    print('Reading in the train and test data')\n",
    "    df_train = pd.read_pickle(train_file).reset_index(drop=True)\n",
    "    df_test = pd.read_pickle(test_file).reset_index(drop=True)\n",
    "    \n",
    "    print('Creating classifier')\n",
    "    nb = NaiveBayesSentimentClassifier()\n",
    "    \n",
    "    print('Training the classifier')\n",
    "    nb.train(df_train)\n",
    "    \n",
    "    print('Making predictions')\n",
    "    nb.predict(df_test['CleanReview'])\n",
    "    \n",
    "    print('Evaluating predictions')\n",
    "    nb.evaluate(df_test['Label'])\n",
    "    \n",
    "    print(f'All done! You achieved {nb.accuracy * 100:.2f}% accuracy!')\n",
    "    return nb\n",
    "\n",
    "def run_test_file(test_file):\n",
    "    reviews = read_test_file(test_file)\n",
    "    nb.predict(reviews)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a77ef20-bc5b-4969-96d0-bb921cfc71ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T11:37:11.714019Z",
     "iopub.status.busy": "2023-02-22T11:37:11.713021Z",
     "iopub.status.idle": "2023-02-22T11:37:13.004150Z",
     "shell.execute_reply": "2023-02-22T11:37:13.002241Z",
     "shell.execute_reply.started": "2023-02-22T11:37:11.714019Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (1800, 4), Testing data: (200, 4)\n"
     ]
    }
   ],
   "source": [
    "path = '../data/txt_sentoken'\n",
    "df = create_dataframe('../data/txt_sentoken')\n",
    "df['CleanReview'] = df['Review'].apply(clean_review)\n",
    "\n",
    "ratio = 0.9\n",
    "train_num = int(1000 * ratio)\n",
    "test_num = 1000 - train_num\n",
    "df_train = pd.concat([df.iloc[:train_num,:],df.iloc[1000:train_num + 1000,:]]).reset_index()\n",
    "df_test = pd.concat([df.iloc[1000 - test_num:1000,:],df.iloc[-test_num:,:]]).reset_index()\n",
    "df_train.to_pickle('../data/train.pkl')\n",
    "df_test.to_pickle('../data/test.pkl')\n",
    "\n",
    "print(f'Training data: {df_train.shape}, Testing data: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e50597a-e0f7-41cb-bf3e-c7dea36852f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T11:37:13.006019Z",
     "iopub.status.busy": "2023-02-22T11:37:13.006019Z",
     "iopub.status.idle": "2023-02-22T11:37:14.985871Z",
     "shell.execute_reply": "2023-02-22T11:37:14.983922Z",
     "shell.execute_reply.started": "2023-02-22T11:37:13.006019Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in the train and test data\n",
      "Creating classifier\n",
      "Training the classifier\n",
      "Making predictions\n",
      "Evaluating predictions\n",
      "All done! You achieved 84.00% accuracy!\n"
     ]
    }
   ],
   "source": [
    "nb = run_naive_bayes('../data/train.pkl', '../data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283f3936-668c-4535-8654-8b057d7d3dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T11:37:14.988372Z",
     "iopub.status.busy": "2023-02-22T11:37:14.987871Z",
     "iopub.status.idle": "2023-02-22T11:37:15.032872Z",
     "shell.execute_reply": "2023-02-22T11:37:15.030870Z",
     "shell.execute_reply.started": "2023-02-22T11:37:14.988372Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    negative\n",
      "1    positive\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "nb = run_test_file('../data/test_cases.txt')\n",
    "print(nb.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "336a37fb-f521-4c2f-9b8d-ff42e2c9f1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T11:37:15.035105Z",
     "iopub.status.busy": "2023-02-22T11:37:15.035105Z",
     "iopub.status.idle": "2023-02-22T11:37:16.240558Z",
     "shell.execute_reply": "2023-02-22T11:37:16.238810Z",
     "shell.execute_reply.started": "2023-02-22T11:37:15.035105Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
