{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BERT Word Selection\nIn this notebook, I take a basic implementation of BERT for Sentiment Analysis and try to improve it the accuracy using text selection or summarization.","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:44:16.159961Z","iopub.execute_input":"2023-04-05T11:44:16.160342Z","iopub.status.idle":"2023-04-05T11:44:16.170566Z","shell.execute_reply.started":"2023-04-05T11:44:16.160308Z","shell.execute_reply":"2023-04-05T11:44:16.168888Z"}}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-05T10:42:01.409939Z","iopub.execute_input":"2023-04-05T10:42:01.410368Z","iopub.status.idle":"2023-04-05T10:42:01.423616Z","shell.execute_reply.started":"2023-04-05T10:42:01.410326Z","shell.execute_reply":"2023-04-05T10:42:01.422575Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-04-05T10:42:01.425372Z","iopub.execute_input":"2023-04-05T10:42:01.425735Z","iopub.status.idle":"2023-04-05T10:42:11.733768Z","shell.execute_reply.started":"2023-04-05T10:42:01.425698Z","shell.execute_reply":"2023-04-05T10:42:11.732645Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.2)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.13.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.9.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.11.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2023.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-04-05T10:42:14.725791Z","iopub.execute_input":"2023-04-05T10:42:14.726262Z","iopub.status.idle":"2023-04-05T10:42:25.145116Z","shell.execute_reply.started":"2023-04-05T10:42:14.726221Z","shell.execute_reply":"2023-04-05T10:42:25.143635Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install gensim==3.8.3","metadata":{"execution":{"iopub.status.busy":"2023-04-05T10:44:16.043249Z","iopub.execute_input":"2023-04-05T10:44:16.043759Z","iopub.status.idle":"2023-04-05T10:44:29.086577Z","shell.execute_reply.started":"2023-04-05T10:44:16.043714Z","shell.execute_reply":"2023-04-05T10:44:29.085415Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim==3.8.3 in /opt/conda/lib/python3.7/site-packages (3.8.3)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim==3.8.3) (1.7.3)\nRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim==3.8.3) (1.21.6)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==3.8.3) (6.3.0)\nRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim==3.8.3) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, pipeline, AdamW\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport pandas as pd\nfrom gensim.summarization import summarize\nimport nltk\nimport spacy\nimport re\n\nnlp = spacy.load(\"en_core_web_sm\")\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2023-04-05T12:11:09.789283Z","iopub.execute_input":"2023-04-05T12:11:09.790794Z","iopub.status.idle":"2023-04-05T12:11:10.514957Z","shell.execute_reply.started":"2023-04-05T12:11:09.790743Z","shell.execute_reply":"2023-04-05T12:11:10.513771Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"raw_datasets = load_dataset(\"imdb\")","metadata":{"execution":{"iopub.status.busy":"2023-04-05T10:45:09.082874Z","iopub.execute_input":"2023-04-05T10:45:09.083527Z","iopub.status.idle":"2023-04-05T10:45:41.903280Z","shell.execute_reply.started":"2023-04-05T10:45:09.083477Z","shell.execute_reply":"2023-04-05T10:45:41.902106Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f172041ed0cc4b678b2bae5e4ccdb42c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"177934189e5740279f87009d8d2ea3db"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0183d2d924aa4fd38e5f9fb193456592"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c452a3f126a84b1cada4234875dcc97e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6fbfb29d3914fa597496e892e6775ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2948f0da9a54af9b87d42930eccbb89"}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33b1c4ce3e44133a4419f859ff7ef7a"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = raw_datasets['train'].shuffle(seed=42).select(range(2000))\ntest_dataset = raw_datasets['test'].shuffle(seed=42).select(range(1000))\nprint(len(train_dataset))\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-04-05T10:45:41.905814Z","iopub.execute_input":"2023-04-05T10:45:41.906797Z","iopub.status.idle":"2023-04-05T10:45:41.947505Z","shell.execute_reply.started":"2023-04-05T10:45:41.906756Z","shell.execute_reply":"2023-04-05T10:45:41.946422Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"2000\n1000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the models","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2023-04-05T10:45:41.949459Z","iopub.execute_input":"2023-04-05T10:45:41.949817Z","iopub.status.idle":"2023-04-05T10:45:48.464232Z","shell.execute_reply.started":"2023-04-05T10:45:41.949782Z","shell.execute_reply":"2023-04-05T10:45:48.463020Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"914d475fa5424934a1cb25b79e112f8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545e5082b8f64ef5bcdf35bfa5f31ced"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3317f12595c4ea5b2acbed21215af18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ee5cd5cb6844441a5f07dfa549bc819"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c0229d92f95441b83f1c7c3dcb04f3d"}},"metadata":{}}]},{"cell_type":"code","source":"# Defining metrics to be used for all models\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    metric = load_metric(\"accuracy\")\n    return metric.compute(predictions=predictions, references=labels)\n\n\ntraining_args = TrainingArguments(\"test_trainer\",evaluation_strategy=\"epoch\")","metadata":{"execution":{"iopub.status.busy":"2023-04-05T12:50:56.448521Z","iopub.execute_input":"2023-04-05T12:50:56.449294Z","iopub.status.idle":"2023-04-05T12:50:56.460348Z","shell.execute_reply.started":"2023-04-05T12:50:56.449256Z","shell.execute_reply":"2023-04-05T12:50:56.459152Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"## Basic Method","metadata":{}},{"cell_type":"code","source":"def tokenize_dataset(dataset,tokenizer):\n    tokenized_dataset = []\n    for item in dataset:\n        tokenized = tokenizer(item[\"text\"],padding=\"max_length\", truncation=True)\n        item.update(tokenized)\n        tokenized_dataset.append(item)\n    return tokenized_dataset\n\ntokenized_train = tokenize_dataset(train_dataset,tokenizer)\ntokenized_test = tokenize_dataset(test_dataset,tokenizer)\n\ntrainer = Trainer(\n    model=model, \n    args=training_args, \n    train_dataset=tokenized_train, \n    eval_dataset=tokenized_test,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:14:38.899770Z","iopub.execute_input":"2023-04-05T11:14:38.900707Z","iopub.status.idle":"2023-04-05T11:14:42.908569Z","shell.execute_reply.started":"2023-04-05T11:14:38.900670Z","shell.execute_reply":"2023-04-05T11:14:42.906946Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.evaluate(tokenized_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:14:42.915869Z","iopub.execute_input":"2023-04-05T11:14:42.916648Z","iopub.status.idle":"2023-04-05T11:20:52.521580Z","shell.execute_reply.started":"2023-04-05T11:14:42.916563Z","shell.execute_reply":"2023-04-05T11:20:52.520454Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 06:08, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.500848</td>\n      <td>0.878000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.669341</td>\n      <td>0.870000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.716820</td>\n      <td>0.882000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.06979254659016927, metrics={'train_runtime': 369.5475, 'train_samples_per_second': 16.236, 'train_steps_per_second': 1.015, 'total_flos': 1578666332160000.0, 'train_loss': 0.06979254659016927, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"The accuracy received from the basic method is 88.2%","metadata":{}},{"cell_type":"markdown","source":"## Word Selection\nIn this section:\n- I use regex to remove HTML tagging.\n- I use the Gensim Library to summarize the text to 512 token after checking token count.\n- I use the tokenizer to prepare the text for training","metadata":{}},{"cell_type":"code","source":"from gensim.summarization import summarize\n\n# Select the most representative sentence for each review using TextRank\ndef process_reviews(dataset, tokenizer, word_count=512):\n    reviews = []\n    for item in dataset:\n        text = item['text']\n        \n        # Define a regular expression pattern to match HTML tags\n        html_tags_pattern = re.compile(r'<.*?>')\n\n        # Replace HTML tags with an empty string\n        text = re.sub(html_tags_pattern, ' ', text)\n        \n        # Check if over word count and summarize\n        if len(text.strip().split()) > word_count:\n            text = summarize(text, word_count=word_count)\n            item.update({'text': text})\n        \n        # Tokenize the text\n        tokenized = tokenizer(text, padding=\"max_length\", truncation=True)\n        item.update(tokenized)\n        reviews.append(item)\n    return reviews\n\n# Select the most representative sentence for each review in train and test dataset\ntokenized_train = process_reviews(train_dataset, tokenizer)\ntokenized_test = process_reviews(test_dataset, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T12:52:11.825058Z","iopub.execute_input":"2023-04-05T12:52:11.825886Z","iopub.status.idle":"2023-04-05T12:52:17.412228Z","shell.execute_reply.started":"2023-04-05T12:52:11.825844Z","shell.execute_reply":"2023-04-05T12:52:17.410975Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# Define the training arguments\ntraining_args = TrainingArguments(\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=500,\n    evaluation_strategy='steps',\n    eval_steps=500,\n    save_total_limit=1,\n    save_strategy='steps',\n    save_steps=500\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T12:52:20.862943Z","iopub.execute_input":"2023-04-05T12:52:20.863636Z","iopub.status.idle":"2023-04-05T12:52:20.874768Z","shell.execute_reply.started":"2023-04-05T12:52:20.863597Z","shell.execute_reply":"2023-04-05T12:52:20.873502Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model, \n    args=training_args, \n    train_dataset=tokenized_train, \n    eval_dataset=tokenized_test,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T12:52:23.084241Z","iopub.execute_input":"2023-04-05T12:52:23.084720Z","iopub.status.idle":"2023-04-05T12:52:23.103542Z","shell.execute_reply.started":"2023-04-05T12:52:23.084681Z","shell.execute_reply":"2023-04-05T12:52:23.102205Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.evaluate(tokenized_test)","metadata":{"trusted":true},"execution_count":90,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 04:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8/8 00:13]\n    </div>\n    "},"metadata":{}},{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.0537279844284058,\n 'eval_accuracy': 0.888,\n 'eval_runtime': 16.6963,\n 'eval_samples_per_second': 59.894,\n 'eval_steps_per_second': 0.479,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"The accuracy for the test data is 88.8% which is 0.6% greater than the training data accuracy of 88.2%. Therefore, the summarization method is just as good if not better than the basic method.","metadata":{}},{"cell_type":"markdown","source":"# ChatGPT API\n\nI tried using the ChatGPT API to summarize the text and then use that for tokenization and sentiment analysis, however I ran out of credits on the plan I was on and was unable to use the API. Below is the code I had planned to use.","metadata":{}},{"cell_type":"code","source":"pip install openai","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:21:30.216073Z","iopub.execute_input":"2023-04-05T11:21:30.217099Z","iopub.status.idle":"2023-04-05T11:21:41.060575Z","shell.execute_reply.started":"2023-04-05T11:21:30.217027Z","shell.execute_reply":"2023-04-05T11:21:41.059170Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting openai\n  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nInstalling collected packages: openai\nSuccessfully installed openai-0.27.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import openai\nopenai.api_key = \"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\"\n\ndef summarize_chatgpt(prompt, model, length=512):\n    response = openai.Completion.create(\n      engine=model,\n      prompt=prompt,\n      max_tokens=length,\n      n=1,\n      stop=None,\n      temperature=0.5,\n    )\n\n    summary = response.choices[0].text.strip()\n    return summary\n","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:41:01.086230Z","iopub.execute_input":"2023-04-05T11:41:01.086607Z","iopub.status.idle":"2023-04-05T11:41:01.094731Z","shell.execute_reply.started":"2023-04-05T11:41:01.086573Z","shell.execute_reply":"2023-04-05T11:41:01.093651Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Select the most representative sentence for each review using TextRank\ndef process_reviews_chatgpt(dataset, tokenizer):\n    start_prompt = \"\"\"I am performing sentiment analyis on the text below. \n    Summarize the text so that it captures the key information to be used in sentiment analysis and obeys a 512 token count. \n    Remove any HTML tags and ensure that the returned text is grammatically correct.\n    Only return the summarized in your response.\n\n    START OF TEXT TO BE SUMMARIZED\n    -------------------------------\n    \"\"\"\n    end_prompt = \"\"\"----------------------------\n    END OF TEXT TO BE SUMMARIZED\"\"\"\n    model = \"davinci\"\n    reviews = []\n    for item in dataset:\n        \n        # Process text using text\n        prompt = start_prompt + item['text'] + end_prompt        \n        text = summarize_chatgpt(prompt, model)\n        \n        # Tokenize the text\n        tokenized = tokenizer(text, padding=\"max_length\", truncation=True)\n        item.update(tokenized)\n        reviews.append(item)\n    return reviews\n\n# Select the most representative sentence for each review in train and test dataset\ntokenized_train = process_reviews_chatgpt(train_dataset, tokenizer)\ntokenized_test = process_reviews_chatgpt(test_dataset, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:41:04.578494Z","iopub.execute_input":"2023-04-05T11:41:04.579626Z","iopub.status.idle":"2023-04-05T11:41:04.797853Z","shell.execute_reply.started":"2023-04-05T11:41:04.579574Z","shell.execute_reply":"2023-04-05T11:41:04.790446Z"},"trusted":true},"execution_count":58,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_351/3417104311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Select the most representative sentence for each review in train and test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtokenized_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_reviews_chatgpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mtokenized_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_reviews_chatgpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_351/3417104311.py\u001b[0m in \u001b[0;36mprocess_reviews_chatgpt\u001b[0;34m(dataset, tokenizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Process text using text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_prompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mend_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_chatgpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Tokenize the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_351/1702903720.py\u001b[0m in \u001b[0;36msummarize_chatgpt\u001b[0;34m(prompt, model, length)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m                 ),\n\u001b[1;32m    626\u001b[0m                 \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             raise self.handle_error_response(\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m             )\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."],"ename":"RateLimitError","evalue":"You exceeded your current quota, please check your plan and billing details.","output_type":"error"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\"test_trainer\",evaluation_strategy=\"epoch\")\n\n\n\ntrainer = Trainer(\n    model=model, \n    args=training_args, \n    train_dataset=tokenized_train, \n    eval_dataset=tokenized_test,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:32:35.905851Z","iopub.execute_input":"2023-04-05T11:32:35.910214Z","iopub.status.idle":"2023-04-05T11:32:35.990024Z","shell.execute_reply.started":"2023-04-05T11:32:35.910164Z","shell.execute_reply":"2023-04-05T11:32:35.988886Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate(tokenized_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:38:46.289250Z","iopub.execute_input":"2023-04-05T11:38:46.290321Z","iopub.status.idle":"2023-04-05T11:39:04.933987Z","shell.execute_reply.started":"2023-04-05T11:38:46.290281Z","shell.execute_reply":"2023-04-05T11:39:04.932694Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.784658670425415,\n 'eval_accuracy': 0.887,\n 'eval_runtime': 18.6305,\n 'eval_samples_per_second': 53.675,\n 'eval_steps_per_second': 3.382,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-04-05T11:32:35.993179Z","iopub.execute_input":"2023-04-05T11:32:35.994234Z","iopub.status.idle":"2023-04-05T11:38:46.287654Z","shell.execute_reply.started":"2023-04-05T11:32:35.994195Z","shell.execute_reply":"2023-04-05T11:38:46.285341Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 06:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.760983</td>\n      <td>0.862000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.701050</td>\n      <td>0.888000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.784659</td>\n      <td>0.887000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.042518933614095054, metrics={'train_runtime': 370.2278, 'train_samples_per_second': 16.206, 'train_steps_per_second': 1.013, 'total_flos': 1578666332160000.0, 'train_loss': 0.042518933614095054, 'epoch': 3.0})"},"metadata":{}}]}]}