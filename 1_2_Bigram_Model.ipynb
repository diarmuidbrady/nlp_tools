{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3b30e7-2188-4f99-a3e4-c4cf34b60f37",
   "metadata": {},
   "source": [
    "# Bigram Model\n",
    "> This module contains a class called `Bigram` and it is a language model capable of printing of the probabilities of text occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad93a74-8a14-4e32-91b0-22f32f04b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f62503-9d36-4f72-a641-47fa06c28cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b51461-36a8-4d92-8484-96878a21d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BigramModel:\n",
    "    '''\n",
    "    The BigramModel class takes a corpus as input. \n",
    "    The corpus is a list of sentence strings.\n",
    "    Each word or token is separated by spaces.\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 corpus:list # This is the training corpus for input\n",
    "                ):\n",
    "\n",
    "        self.corpus = corpus\n",
    "\n",
    "        # Create a list of lists representing each sentence\n",
    "        self.sentences = [sentence.split() for sentence in self.corpus]\n",
    "        \n",
    "        # Create a list of tokens from sentences\n",
    "        self.tokens = [word for sentence in self.sentences for word in sentence]\n",
    "        \n",
    "        # bigram_counts contains the counts of each bigram in the corpus\n",
    "        self.bigram_counts = {}\n",
    "        \n",
    "        # word_counts contains the counts of the first word in each bigram\n",
    "        self.word_counts = {}\n",
    "        for sentence in self.sentences:\n",
    "            # start index at 1 and look back one for each bigram\n",
    "            for i in range(1, len(sentence)):\n",
    "                prev_word, next_word = sentence[i-1], sentence[i]\n",
    "                \n",
    "                # Check if we have seen this bigram before\n",
    "                if prev_word in self.word_counts:\n",
    "                    self.word_counts[prev_word] += 1\n",
    "                    \n",
    "                # else we add it to the dictionary\n",
    "                else:\n",
    "                    self.word_counts[prev_word] = 1\n",
    "\n",
    "                bigram = (prev_word, next_word)\n",
    "                                    \n",
    "                if bigram in self.bigram_counts:\n",
    "                    self.bigram_counts[bigram] += 1\n",
    "                else:\n",
    "                    self.bigram_counts[bigram] = 1\n",
    "                    \n",
    "        # bigram_probabilities contains the probabilities of each bigram in the corpus\n",
    "        self.bigram_probabilities = {}\n",
    "        for bigram in self.bigram_counts:\n",
    "            prev_word = bigram[0]\n",
    "            \n",
    "            # Given a previous word what is the bigram probability?\n",
    "            probability = self.bigram_counts[bigram] / self.word_counts[prev_word]\n",
    "            self.bigram_probabilities[bigram] = probability\n",
    "\n",
    "    def get_bigram_probability(self,\n",
    "                               bigram:list # list of 2 strings\n",
    "                              ):\n",
    "        '''\n",
    "        Returns a probability for a given bigram input.\n",
    "        \n",
    "        Example:\n",
    "        model = BigramModel(corpus)\n",
    "        print(model.get_bigram_probability(['c' 'b']))\n",
    "        \n",
    "        >> 0.25\n",
    "        '''\n",
    "        \n",
    "        # Check if the bigram exists else return zero\n",
    "        if bigram in self.bigram_probabilities:\n",
    "            return self.bigram_probabilities[bigram]\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def get_string_probability(self,\n",
    "                               string:str # a normal sentence\n",
    "                              ):\n",
    "        '''\n",
    "        Returns the probability of a string of text\n",
    "        \n",
    "        Example:\n",
    "        model = BigramModel(corpus)\n",
    "        print(model.get_string_probability('c b')\n",
    "        \n",
    "        >> 0.25\n",
    "        '''\n",
    "        tokens = string.split()\n",
    "        probability = self.tokens.count(tokens[0]) / len(self.tokens)\n",
    "        for i in range(1, len(tokens)):\n",
    "            bigram = (tokens[i-1], tokens[i])\n",
    "            probability *= self.get_bigram_probability(bigram)\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40595d-68d6-4745-90e1-8dd5dcd4f1fd",
   "metadata": {},
   "source": [
    "Here are some example strings and their probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e85df-7b93-4da2-8ee0-44d5d52fd7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c     : 0.5\n",
      "b     : 0.5\n",
      "b c   : 0.25\n",
      "b b   : 0.25\n",
      "b c b : 0.125\n"
     ]
    }
   ],
   "source": [
    "corpus = ['b c', 'c c', 'c b', 'b b']\n",
    "model = BigramModel(corpus)\n",
    "for string in ['c', 'b', 'b c', 'b b', 'b c b']:\n",
    "    print(f'{string.ljust(6)}: {model.get_string_probability(string)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab3934-e3c2-41cb-8bde-fa65d020f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(model.get_string_probability('c'), 0.5)\n",
    "test_eq(model.get_string_probability('c b'), 0.25)\n",
    "test_eq(model.get_string_probability('c b c'), 0.125)\n",
    "test_ne(model.get_string_probability('c'), 0)\n",
    "test_ne(model.get_string_probability('c b'), 0)\n",
    "test_ne(model.get_string_probability('c b c'), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e3257-5c21-4b05-8b95-437ee7fd3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
